{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Module 5, Lab 4 - Factorial Designs\n===================================\n\nIn this lab, we will explore the factorial experiment. I analyze the\ndata from the previous lab but using a factorial design. I assume you\nare familiar with the between subjects lab, conducted previously. In\nthis lab, we consider whether the three logos have different effects for\nmales or females, a question which marketing wants to know prior to\npushing the ad to different markets.\n\nBefore we begin, I will load the packages required to run this notebook:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "## LOAD PACKAGES \nimport pandas as pd\nimport numpy as np\nimport scipy.stats as ss\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.anova import anova_lm\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\nfrom statsmodels.graphics.factorplots import interaction_plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Next, the dataset is loaded and the sentiment is computed:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "## Load the dataset\ndat = pd.read_csv(\"datasets/logos.csv\")\n\n## Remove rows with missing values \ndat.dropna(subset = ['logo'], inplace = True)\n\n## Compute sentiment and look at the head of the data frame.\ndat['sentiment'] = dat[['friendly', 'inviting', 'interesting', 'positive', 'pleasant']].apply(np.mean, axis = 1)\ndat.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finally, we need the specialized Python pyDOE package for designed experiments, which must be installed and imported:"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Vizualize the Data + Run Descriptives\n=====================================\n\nIn a factorial design, we randomly assign a second treatment in addition\nto the first. For example, we could also make 50% of the logos in color\nand 50% in grey scale. Thus we would randomly assign people to one of\nthe designs (3 levels: A, B, and C) and one of the colors (2 levels:\ncolor, grey scale). For this reason, this is referred to as a 2 x 3\nfactorial design.\n\nOne need not randomly assign the variable. One can also use a\npre-existing grouping variable, such as sex. One caveat is needed,\nhowever; if the grouping variable was not randomly assigned to\nparticipants (e.g., favorite color), we cannot be sure if any observed\neffect is due to that variable or something else that might be causing\nit. For example, if participants who love the color purple tend to\nprefer Logo B, we don't know if that logo preference is due to the color\nor something else that might cause that color preference (see the\ndiscussion on prior causes in the regression lab).\n\nIn our case, we will examine a 2 (sex: male, female) x 3 (logo: A, B, C)\ndesign. These combinations define our *factorial design**.\nAlthough it is true that sex was not randomly assigned by the\nresearch team to participants, biological sex is randomly assigned at\nbirth and has no known prior causes. Thus, any differences we see\nbetween the sexes can be ultimately assumed to result from sex.\n\nWe can easily visualize our data using the seaborn package. You already performed visualization of sentiment by logo in a previous lab. Now, you can create a visualization by sex. "
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "ax = plt.figure(figsize=(8,8)).gca() # define axis\nsns.boxplot(x = 'sex', y = 'sentiment', data = dat, ax = ax)\nsns.swarmplot(x = 'sex', y = 'sentiment', color = 'black', data = dat, ax = ax, alpha = 0.4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There is not a great deal of difference in sentiment by sex. \n\nNow, you will visualize the interaction between sentiment and logo and sex. In this case we use the `hue` arguments to differentiate between male and female:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "ax = plt.figure(figsize=(8,8)).gca() # define axis\nsns.boxplot(x = 'logo', y = 'sentiment', data = dat, hue = 'sex', ax = ax)\nsns.swarmplot(x = 'logo', y = 'sentiment', hue = 'sex', data = dat, ax = ax, alpha = 0.4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We do not see any large systematic differences in the overall levels of\nsentiment for males or females, nor do we see a substantively different\npattern of liking across the three logos for males or females. Thus,\nperhaps sex does not matter much. \n\nThe Pandas `groupby` method can operate on multiple grouping columns. The code in the cell below groups the data by levels of both `logo` and `sex` and then computes and displays the mean and standard deviation:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "dat_grouped = dat[['sentiment','logo','sex']].groupby(['logo','sex'])\nprint('The means of the groups:')\nprint(dat_grouped.mean())\nprint('\\n')\nprint('The standard deviations of the groups:')\nprint(dat_grouped.std())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As you could see from the box plots, there is some difference in the means of these groups. Additionally, the variance of the groups varies a fair amount. This lack of *homogeneity of variance* between the groups violates one of the assumptions of ANOVA and may prove to be a problem.  \n\nNext, we can conduct the factorial ANOVA. In general, the ANOVA assesses\nwhether:\n\n1.  There are significant differences between the two sexes (similar to\n    a one-way ANOVA or t-test)\n2.  There are significant differences between the three logos (similar\n    to a one-way ANOVA or t-test)\n3.  The two variables interact\n\nI consider these three questions next.\n\nExample with Interaction Term:\n==============================\n\nNow we need to create an ANOVA model with the *interaction term* between `sex` and `logo`. An interaction term is just what you might think. Interactions are cases where \"one variable influences the effect of\nanother.\" So, the sex x logo interaction is asking: \"is there a\ndifferent pattern of differences between the logos for males than for\nfemales?\" This is not the same as asking whether males or females have\ndifferent levels of sentiment. Instead, we are asking whether the effect\nof `logo` is different at different levels of `sex`. You can also reverse this. This is the same as asking whether the effect\nof `sex` is different across the three `logos`. An interaction is\nessentially one variable influencing the effectiveness of another.\n\nFactorial ANOVA designs can get tricky. The best way to conduct the\nanalysis for real-world data in Python is to use the `ols` function from statsmodels.formula.api package. The `anova_lm` function from the statsmodels.stats.anova package is then applied to the linear model object created with `ols` We need to select the \"type\" of ANOVA analysis. Since we are including an interaction term in our design we will use `type = 3`. \n\nNote that the strictly speaking, the\n`aov_lm()` model assumes perfectly\nbalanced factorial designs (equal numbers of people in every permutation\nof the experiment, no missing data). This assumption is not adhered to in this case. \n\nThe `ols` function uses a *model formula* of the form:\n\n$$dependent variable \\sim independent_var1\\ +\\ independent_var2\\ + \\ldots +\\ independent_var1:independent_var2 \\\\\nwhere\\\\\nindependent_var1:independent_var2 = interaction\\ term$$\n\nSuch model formulas give us a great deal of flexibility in defining factorial design of our experiment:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "formula = 'sentiment ~ C(logo) + C(sex) + C(logo):C(sex)'\nlm_model = ols(formula, dat).fit()\naov_table = anova_lm(lm_model, typ=2)\nprint(aov_table)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "What can you make of this output? You can be interpret these results as follows:\n\n1.  There is not a significant sex difference overall, since the F-statistic is small and the p-value is large. \n2.  There are significant differences between the logos, since the F-statistic is large and the p-value is small. \n3.  There is not a significant \"interaction\" between sex and logo, since the F-statistic is small and the p-value is large.\n\nIt's worth remembering that a non-significant effect does *not* mean\nthat there is zero effect. We can easily see the 95% CIs for our\n\"non-significant\" effects with Tukey's HSD test. This must be done in two steps:\n\n1. Create a new variable which represents the interaction term before `sex` and `logo`.\n2. Compute and display the results of the Tukey HSD on the interaction term. "
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "## Create a new variable to represent the interaction term\ndat['logo_sex'] = [x.replace(\" \", \"\") + '_' + y for x,y in zip(dat.logo,dat.sex)]\n\n# Run the Tukey HDS test using the interaction variable and display the results\nTukey_HSD = pairwise_tukeyhsd(dat.sentiment,dat.logo_sex)\nprint(Tukey_HSD)\nTukey_HSD.plot_simultaneous()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "For the most part, it is the differences between logo C and the other logos that are significant, for either sex. The one exception, is logo A for male subjects which has an exceptionally wide confidence interval. "
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}